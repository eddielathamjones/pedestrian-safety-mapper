{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FARS Multi-Sensory Database - Exploratory Analysis\n",
    "\n",
    "This notebook demonstrates basic analysis of the pedestrian crash database.\n",
    "\n",
    "**Topics covered:**\n",
    "- Database connection\n",
    "- Data quality assessment\n",
    "- Geographic visualization\n",
    "- Environmental factor analysis\n",
    "- Multi-sensory crash profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Project imports\n",
    "from src.database import Database\n",
    "from src.utils.geo_utils import calculate_distance\n",
    "from src.utils.validation import DataQualityChecker\n",
    "\n",
    "# Plotting setup\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"✓ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to database\n",
    "db = Database()\n",
    "\n",
    "if db.test_connection():\n",
    "    print(\"✓ Database connection successful\")\n",
    "else:\n",
    "    print(\"✗ Database connection failed\")\n",
    "    raise Exception(\"Cannot connect to database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics from database\n",
    "summary = db.execute(\"SELECT * FROM vw_database_summary;\")\n",
    "\n",
    "if summary:\n",
    "    summary_df = pd.DataFrame(\n",
    "        [summary[0]],\n",
    "        columns=[\n",
    "            'total_crashes', 'states_covered', 'counties_covered',\n",
    "            'crashes_with_streetview', 'crashes_with_sound',\n",
    "            'crashes_with_air_quality', 'crashes_with_weather',\n",
    "            'streetview_coverage_pct', 'sound_coverage_pct',\n",
    "            'aq_coverage_pct', 'weather_coverage_pct'\n",
    "        ]\n",
    "    ).T\n",
    "    summary_df.columns = ['Value']\n",
    "    print(\"Database Summary:\")\n",
    "    print(summary_df)\n",
    "else:\n",
    "    print(\"No data in database yet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load crash data\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    crash_id,\n",
    "    state,\n",
    "    city,\n",
    "    county,\n",
    "    latitude,\n",
    "    longitude,\n",
    "    crash_date,\n",
    "    crash_time,\n",
    "    time_of_day,\n",
    "    severity,\n",
    "    vehicle_speed\n",
    "FROM crashes\n",
    "LIMIT 1000;\n",
    "\"\"\"\n",
    "\n",
    "crashes = pd.read_sql(query, db._engine)\n",
    "print(f\"Loaded {len(crashes):,} crashes\")\n",
    "crashes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data completeness\n",
    "completeness_query = \"\"\"\n",
    "SELECT \n",
    "    has_streetview,\n",
    "    has_sound,\n",
    "    has_air_quality,\n",
    "    has_weather,\n",
    "    has_lighting,\n",
    "    has_analysis,\n",
    "    completeness_percentage\n",
    "FROM vw_data_completeness\n",
    "ORDER BY completeness_percentage DESC\n",
    "LIMIT 100;\n",
    "\"\"\"\n",
    "\n",
    "completeness = pd.read_sql(completeness_query, db._engine)\n",
    "\n",
    "# Plot completeness distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(completeness['completeness_percentage'], bins=20, edgecolor='black')\n",
    "plt.xlabel('Completeness Percentage')\n",
    "plt.ylabel('Number of Crashes')\n",
    "plt.title('Data Completeness Distribution')\n",
    "plt.axvline(completeness['completeness_percentage'].mean(), \n",
    "            color='red', linestyle='--', label=f'Mean: {completeness[\"completeness_percentage\"].mean():.1f}%')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average completeness: {completeness['completeness_percentage'].mean():.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Geographic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crashes by state\n",
    "crashes_by_state = crashes['state'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "crashes_by_state.head(10).plot(kind='bar')\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Number of Crashes')\n",
    "plt.title('Top 10 States by Pedestrian Crashes')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive map of crashes (sample)\n",
    "sample_crashes = crashes.dropna(subset=['latitude', 'longitude']).sample(min(100, len(crashes)))\n",
    "\n",
    "# Center map on mean coordinates\n",
    "center_lat = sample_crashes['latitude'].mean()\n",
    "center_lon = sample_crashes['longitude'].mean()\n",
    "\n",
    "# Create map\n",
    "m = folium.Map(location=[center_lat, center_lon], zoom_start=10)\n",
    "\n",
    "# Add crash markers\n",
    "for idx, crash in sample_crashes.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[crash['latitude'], crash['longitude']],\n",
    "        radius=5,\n",
    "        popup=f\"{crash['crash_id']}<br>{crash['city']}<br>{crash['crash_date']}\",\n",
    "        color='red',\n",
    "        fill=True,\n",
    "        fillColor='red',\n",
    "        fillOpacity=0.6\n",
    "    ).add_to(m)\n",
    "\n",
    "# Display map\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Temporal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crashes by time of day\n",
    "time_of_day_counts = crashes['time_of_day'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "time_of_day_counts.plot(kind='bar', color=['#FFD700', '#FF6347', '#4169E1', '#2F4F4F'])\n",
    "plt.xlabel('Time of Day')\n",
    "plt.ylabel('Number of Crashes')\n",
    "plt.title('Crashes by Time of Day')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crashes by hour (if crash_time available)\n",
    "crashes_with_time = crashes.dropna(subset=['crash_time'])\n",
    "\n",
    "if len(crashes_with_time) > 0:\n",
    "    # Extract hour from crash_time\n",
    "    crashes_with_time['hour'] = pd.to_datetime(crashes_with_time['crash_time'], format='%H:%M:%S').dt.hour\n",
    "    \n",
    "    hour_counts = crashes_with_time['hour'].value_counts().sort_index()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(hour_counts.index, hour_counts.values, marker='o', linewidth=2, markersize=8)\n",
    "    plt.xlabel('Hour of Day')\n",
    "    plt.ylabel('Number of Crashes')\n",
    "    plt.title('Crashes by Hour of Day')\n",
    "    plt.xticks(range(0, 24))\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No crash time data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Multi-Sensory Analysis (If Data Available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load multi-sensory data for crashes\n",
    "multisensory_query = \"\"\"\n",
    "SELECT \n",
    "    crash_id,\n",
    "    city,\n",
    "    state,\n",
    "    mean_loudness_db,\n",
    "    pm2_5,\n",
    "    aqi_category,\n",
    "    temperature_f,\n",
    "    lighting_condition,\n",
    "    cv_has_crosswalk,\n",
    "    environmental_stress_score,\n",
    "    pedestrian_safety_score\n",
    "FROM vw_crash_complete\n",
    "WHERE data_complete = TRUE\n",
    "LIMIT 100;\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    multisensory = pd.read_sql(multisensory_query, db._engine)\n",
    "    \n",
    "    if len(multisensory) > 0:\n",
    "        print(f\"Loaded {len(multisensory):,} crashes with complete multi-sensory data\")\n",
    "        \n",
    "        # Display first few rows\n",
    "        display(multisensory.head())\n",
    "        \n",
    "        # Correlation matrix\n",
    "        numeric_cols = ['mean_loudness_db', 'pm2_5', 'temperature_f', \n",
    "                       'environmental_stress_score', 'pedestrian_safety_score']\n",
    "        \n",
    "        available_cols = [col for col in numeric_cols if col in multisensory.columns]\n",
    "        \n",
    "        if len(available_cols) > 1:\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            sns.heatmap(\n",
    "                multisensory[available_cols].corr(),\n",
    "                annot=True,\n",
    "                cmap='coolwarm',\n",
    "                center=0,\n",
    "                square=True\n",
    "            )\n",
    "            plt.title('Multi-Sensory Factor Correlation Matrix')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(\"No complete multi-sensory data available yet\")\n",
    "        print(\"Run data collectors to populate environmental data\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Multi-sensory data not available: {e}\")\n",
    "    print(\"This is normal if you haven't run the data collectors yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. High-Risk Location Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find high-risk crashes (if analysis data available)\n",
    "high_risk_query = \"\"\"\n",
    "SELECT \n",
    "    crash_id,\n",
    "    intersection,\n",
    "    city,\n",
    "    state,\n",
    "    risk_factor_count,\n",
    "    environmental_stress_score,\n",
    "    pedestrian_safety_score\n",
    "FROM vw_high_risk_crashes\n",
    "ORDER BY risk_factor_count DESC, environmental_stress_score DESC\n",
    "LIMIT 20;\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    high_risk = pd.read_sql(high_risk_query, db._engine)\n",
    "    \n",
    "    if len(high_risk) > 0:\n",
    "        print(f\"Found {len(high_risk)} high-risk crash locations\")\n",
    "        display(high_risk)\n",
    "        \n",
    "        # Visualize risk factors\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(\n",
    "            high_risk['environmental_stress_score'],\n",
    "            high_risk['pedestrian_safety_score'],\n",
    "            s=high_risk['risk_factor_count'] * 50,\n",
    "            alpha=0.6,\n",
    "            c=high_risk['risk_factor_count'],\n",
    "            cmap='YlOrRd'\n",
    "        )\n",
    "        plt.xlabel('Environmental Stress Score')\n",
    "        plt.ylabel('Pedestrian Safety Score')\n",
    "        plt.title('High-Risk Crashes: Stress vs Safety\\n(Size = Number of Risk Factors)')\n",
    "        plt.colorbar(label='Risk Factor Count')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No high-risk crashes identified yet\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"High-risk analysis not available: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export crash data to CSV\n",
    "output_path = project_root / 'outputs' / 'exports' / 'crash_sample.csv'\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "crashes.to_csv(output_path, index=False)\n",
    "print(f\"✓ Exported {len(crashes):,} crashes to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Next Steps\n",
    "\n",
    "To get more insights:\n",
    "\n",
    "1. **Collect environmental data:**\n",
    "   ```bash\n",
    "   python scripts/03_download_streetview.py --limit 10\n",
    "   python scripts/05_collect_air_quality.py --limit 10\n",
    "   python scripts/06_collect_weather.py --limit 10\n",
    "   ```\n",
    "\n",
    "2. **Run computer vision analysis:**\n",
    "   ```bash\n",
    "   python scripts/07_analyze_images.py\n",
    "   ```\n",
    "\n",
    "3. **Generate comprehensive reports:**\n",
    "   ```bash\n",
    "   python scripts/08_generate_reports.py\n",
    "   ```\n",
    "\n",
    "4. **Explore specific analyses:**\n",
    "   - Environmental justice by county\n",
    "   - Infrastructure deficiency patterns\n",
    "   - Crash clustering and hotspots\n",
    "   - Weather/lighting correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "db.close()\n",
    "print(\"✓ Analysis complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
